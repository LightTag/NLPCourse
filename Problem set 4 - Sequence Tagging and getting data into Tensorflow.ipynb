{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro \n",
    "Esentially, the hardest part in applied Deep NLP is deciding which model to choose and then getting the data into it. \n",
    "\n",
    "In this task, you'll build a neural network that capitalizes letters where they should be. For example given\n",
    "\"this is a lesson by tal perry in berlin\" model should output \"This is a lesson by Tal Perry in Berlin\" \n",
    "\n",
    "Unlike in the previous excercise, you are not given pre made data. You will have to prepare your training data yourself, and get it into a format that \"tensorflow likes\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "Read the blog post [Getting Text into Tensorflow with the dataset API](https://medium.com/@TalPerry/getting-text-into-tensorflow-with-the-dataset-api-ffb832c8bec6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "Use what you learnt in the blog post to put the contents of **./dataforproblem4.txt** into a Tensorflow dataset. \n",
    "Your dataset should include at least two tensors:\n",
    "* **src** A tensor representing the input as all lowercase\n",
    "* **target** A tensor representing the original (multicased) input\n",
    "\n",
    "*You may find it easier to work in eager mode and switch later*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1\n",
    "Look inside utils/dnn/estimatorTools, particularly at the function **input_fn** \n",
    "Copy and modify it so that it works with the dataset you built in task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task  3\n",
    "Build a bidirectional LSTM model as before that given a **src** tensor predicts target. You should do this in the same way as problem 3, e.g. write a function **model** that gets passed to estimator_factory. \n",
    "\n",
    "Use the estimator factory with your new model and input_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
